{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing First Steps with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains basic NLP techniques : text preprocessing, Similarity measures, Sentiment Analysis, text translation, TF-IDF analysis \n",
    "\n",
    "Using different libraries : \n",
    "- **NLTK**\n",
    "- **SpaCy**\n",
    "- **Wordnet**\n",
    "- **Textblob**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, gutenberg\n",
    "\n",
    "# SpaCy\n",
    "# We need to dowmnloead the trained pipelines \"en_core_web_md\" using the code below\n",
    "#!python -m spacy download en_core_web_md\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "#\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", message=r\"\\[W008\\]\", category=UserWarning)\n",
    "\n",
    "# Wordnet\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# TF-IDF\n",
    "import math\n",
    "\n",
    "#\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may need to download some package from NLTK module\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('all') # for wordnet languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### NLTK Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the text document  \"metamorphosis_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'metamorphosis_clean.txt'\n",
    "file = open(filename, 'rt')\n",
    "doc = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text have 119163 characters.\n"
     ]
    }
   ],
   "source": [
    "print('The text have {} characters.'.format(len(doc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the 10 first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One morning, when Gregor Samsa woke from troubled dreams, he found\\nhimself transformed in his bed into a horrible vermin.',\n",
       " 'He lay on\\nhis armour-like back, and if he lifted his head a little he could\\nsee his brown belly, slightly domed and divided by arches into stiff\\nsections.',\n",
       " 'The bedding was hardly able to cover it and seemed ready\\nto slide off any moment.',\n",
       " 'His many legs, pitifully thin compared\\nwith the size of the rest of him, waved about helplessly as he\\nlooked.',\n",
       " '\"What\\'s happened to me?\"',\n",
       " 'he thought.',\n",
       " \"It wasn't a dream.\",\n",
       " 'His room,\\na proper human room although a little too small, lay peacefully\\nbetween its four familiar walls.',\n",
       " 'A collection of textile samples\\nlay spread out on the table - Samsa was a travelling salesman - and\\nabove it there hung a picture that he had recently cut out of an\\nillustrated magazine and housed in a nice, gilded frame.',\n",
       " 'It showed\\na lady fitted out with a fur hat and fur boa who sat upright,\\nraising a heavy fur muff that covered the whole of her lower arm\\ntowards the viewer.']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice the 1rst sentence into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'morning', ',', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', ',', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(sentences[0])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the function of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('One', 'CD'),\n",
       " ('morning', 'NN'),\n",
       " (',', ','),\n",
       " ('when', 'WRB'),\n",
       " ('Gregor', 'NNP'),\n",
       " ('Samsa', 'NNP'),\n",
       " ('woke', 'VBD'),\n",
       " ('from', 'IN'),\n",
       " ('troubled', 'JJ'),\n",
       " ('dreams', 'NNS'),\n",
       " (',', ','),\n",
       " ('he', 'PRP'),\n",
       " ('found', 'VBD'),\n",
       " ('himself', 'PRP'),\n",
       " ('transformed', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('bed', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('horrible', 'JJ'),\n",
       " ('vermin', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first 100 tokenized words of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'morning,', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams,', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin.', 'He', 'lay', 'on', 'his', 'armour-like', 'back,', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly,', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment.', 'His', 'many', 'legs,', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him,', 'waved', 'about', 'helplessly', 'as', 'he', 'looked.', '\"What\\'s', 'happened', 'to', 'me?\"', 'he', 'thought.', 'It', \"wasn't\", 'a', 'dream.', 'His', 'room,', 'a', 'proper', 'human']\n"
     ]
    }
   ],
   "source": [
    "doc_words = doc.split()\n",
    "print(text_words[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'whom', \"shan't\", \"don't\", 'm', 'because', 'from', 'but', 'nor', 'an', 'wouldn', 'again', 'it', \"isn't\", 'each', 'no', \"shouldn't\", 'too', 'yourselves', 'when', 'you', 'of', 'himself', 'to', 'above', 'his', 'shouldn', 'your', 'wasn', 'who', 'through', 'if', 'out', 'aren', 'ma', 'below', 'her', 'why', 'than', 'into', 'their', \"she's\", \"you'll\", \"mightn't\", \"doesn't\", 'some', \"hasn't\", 'under', 'isn', 'a', 'am', \"hadn't\", 'until', \"wouldn't\", 'be', 'where', 'before', 'once', \"couldn't\", 'all', 'don', 'did', 'after', 'at', 'do', 'there', 'about', 'me', 'what', \"you're\", 'very', 'won', 'yours', 'they', 'by', 'for', 'haven', 'so', 'here', 'only', 'more', \"weren't\", 'mightn', 'will', 'shan', 'yourself', 'which', 'as', 'ain', 'y', 'is', 'she', 'myself', 'any', \"you've\", 'then', 'same', \"you'd\", 'herself', 'down', 'didn', 'on', 'in', 'during', 'that', 'most', 'have', 'now', 'been', \"didn't\", 'mustn', 'over', 'those', 'the', 'are', 'ourselves', 'these', 'having', 'should', 'theirs', 'against', \"haven't\", 's', \"aren't\", 'has', 'd', 'further', 'own', 'was', 'doesn', 'hasn', 'does', 'can', \"should've\", 'were', 'he', 'other', 'll', 'weren', 'doing', \"mustn't\", 'ours', 'with', 'how', 'not', 'between', 'had', \"that'll\", 'o', 're', 'hers', \"won't\", 'itself', 'such', 'few', 't', 'we', 'him', 'themselves', 'being', 'this', 'both', 'needn', 'my', 'them', \"it's\", 'and', 'hadn', \"needn't\", 'its', \"wasn't\", 'up', 'just', 'while', 'off', 'or', 've', 'our', 'i', 'couldn'}\n"
     ]
    }
   ],
   "source": [
    "en_stops = set(stopwords.words('english'))\n",
    "print(en_stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all stop words from the text and print the new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new text have 11346 carcahters.\n",
      "\n",
      "['One', 'morning,', 'Gregor', 'Samsa', 'woke', 'troubled', 'dreams,', 'found', 'transformed', 'bed', 'horrible', 'vermin.', 'He', 'lay', 'armour-like', 'back,', 'lifted', 'head', 'little', 'could', 'see', 'brown', 'belly,', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections.', 'The', 'bedding', 'hardly', 'able', 'cover', 'seemed', 'ready', 'slide', 'moment.', 'His', 'many', 'legs,', 'pitifully', 'thin', 'compared', 'size', 'rest', 'him,', 'waved', 'helplessly', 'looked.', '\"What\\'s', 'happened', 'me?\"', 'thought.', 'It', 'dream.', 'His', 'room,', 'proper', 'human', 'room', 'although', 'little', 'small,', 'lay', 'peacefully', 'four', 'familiar', 'walls.', 'A', 'collection', 'textile', 'samples', 'lay', 'spread', 'table', '-', 'Samsa', 'travelling', 'salesman', '-', 'hung', 'picture', 'recently', 'cut', 'illustrated', 'magazine', 'housed', 'nice,', 'gilded', 'frame.', 'It', 'showed', 'lady', 'fitted', 'fur', 'hat', 'fur', 'boa', 'sat']\n"
     ]
    }
   ],
   "source": [
    "text_without_en_stops = []  \n",
    "for w in doc_words:  \n",
    "    if w not in en_stops:  \n",
    "        text_without_en_stops.append(w) \n",
    "print('The new text have {} carcahters.\\n'.format(len(text_without_en_stops)))\n",
    "print(text_without_en_stops[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SpaCy Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'morning', ',', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', ',', 'he', 'found', '\\n', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', '.', ' ', 'He', 'lay', 'on', '\\n', 'his', 'armour', '-', 'like', 'back', ',', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', '\\n', 'see', 'his', 'brown', 'belly', ',', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', '\\n', 'sections', '.', ' ', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', '\\n', 'to', 'slide', 'off', 'any', 'moment', '.', ' ', 'His', 'many', 'legs', ',', 'pitifully', 'thin', 'compared', '\\n', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', ',', 'waved']\n"
     ]
    }
   ],
   "source": [
    "doc_= nlp(doc)\n",
    "word_tokens = [token.text for token in doc_]\n",
    "print(word_tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get position and tag of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('One', 'NUM', 'CD'), ('morning', 'NOUN', 'NN'), (',', 'PUNCT', ','), ('when', 'SCONJ', 'WRB'), ('Gregor', 'PROPN', 'NNP'), ('Samsa', 'PROPN', 'NNP'), ('woke', 'VERB', 'VBD'), ('from', 'ADP', 'IN'), ('troubled', 'ADJ', 'JJ'), ('dreams', 'NOUN', 'NNS'), (',', 'PUNCT', ','), ('he', 'PRON', 'PRP'), ('found', 'VERB', 'VBD'), ('\\n', 'SPACE', '_SP'), ('himself', 'PRON', 'PRP'), ('transformed', 'VERB', 'VBD'), ('in', 'ADP', 'IN'), ('his', 'PRON', 'PRP$'), ('bed', 'NOUN', 'NN'), ('into', 'ADP', 'IN'), ('a', 'DET', 'DT'), ('horrible', 'ADJ', 'JJ'), ('vermin', 'NOUN', 'NN'), ('.', 'PUNCT', '.'), (' ', 'SPACE', '_SP'), ('He', 'PRON', 'PRP'), ('lay', 'VERB', 'VBD'), ('on', 'ADP', 'IN'), ('\\n', 'SPACE', '_SP'), ('his', 'PRON', 'PRP$'), ('armour', 'NOUN', 'NN'), ('-', 'PUNCT', 'HYPH'), ('like', 'NOUN', 'NN'), ('back', 'NOUN', 'NN'), (',', 'PUNCT', ','), ('and', 'CCONJ', 'CC'), ('if', 'SCONJ', 'IN'), ('he', 'PRON', 'PRP'), ('lifted', 'VERB', 'VBD'), ('his', 'PRON', 'PRP$'), ('head', 'NOUN', 'NN'), ('a', 'DET', 'DT'), ('little', 'ADJ', 'JJ'), ('he', 'PRON', 'PRP'), ('could', 'AUX', 'MD'), ('\\n', 'SPACE', '_SP'), ('see', 'VERB', 'VB'), ('his', 'PRON', 'PRP$'), ('brown', 'ADJ', 'JJ'), ('belly', 'NOUN', 'NN'), (',', 'PUNCT', ','), ('slightly', 'ADV', 'RB'), ('domed', 'ADJ', 'JJ'), ('and', 'CCONJ', 'CC'), ('divided', 'VERB', 'VBN'), ('by', 'ADP', 'IN'), ('arches', 'NOUN', 'NNS'), ('into', 'ADP', 'IN'), ('stiff', 'ADJ', 'JJ'), ('\\n', 'SPACE', '_SP'), ('sections', 'NOUN', 'NNS'), ('.', 'PUNCT', '.'), (' ', 'SPACE', '_SP'), ('The', 'DET', 'DT'), ('bedding', 'NOUN', 'NN'), ('was', 'AUX', 'VBD'), ('hardly', 'ADV', 'RB'), ('able', 'ADJ', 'JJ'), ('to', 'PART', 'TO'), ('cover', 'VERB', 'VB'), ('it', 'PRON', 'PRP'), ('and', 'CCONJ', 'CC'), ('seemed', 'VERB', 'VBD'), ('ready', 'ADJ', 'JJ'), ('\\n', 'SPACE', '_SP'), ('to', 'PART', 'TO'), ('slide', 'VERB', 'VB'), ('off', 'ADP', 'RP'), ('any', 'DET', 'DT'), ('moment', 'NOUN', 'NN'), ('.', 'PUNCT', '.'), (' ', 'SPACE', '_SP'), ('His', 'PRON', 'PRP$'), ('many', 'ADJ', 'JJ'), ('legs', 'NOUN', 'NNS'), (',', 'PUNCT', ','), ('pitifully', 'ADV', 'RB'), ('thin', 'ADJ', 'JJ'), ('compared', 'VERB', 'VBN'), ('\\n', 'SPACE', '_SP'), ('with', 'ADP', 'IN'), ('the', 'DET', 'DT'), ('size', 'NOUN', 'NN'), ('of', 'ADP', 'IN'), ('the', 'DET', 'DT'), ('rest', 'NOUN', 'NN'), ('of', 'ADP', 'IN'), ('him', 'PRON', 'PRP'), (',', 'PUNCT', ','), ('waved', 'VERB', 'VBD')]\n"
     ]
    }
   ],
   "source": [
    "pos_tag = [(token.text,token.pos_, token.tag_) for token in doc_]\n",
    "print(pos_tag[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['morning', ',', 'Gregor', 'Samsa', 'woke', 'troubled', 'dreams', ',', 'found', '\\n', 'transformed', 'bed', 'horrible', 'vermin', '.', ' ', 'lay', '\\n', 'armour', '-', 'like', ',', 'lifted', 'head', 'little', '\\n', 'brown', 'belly', ',', 'slightly', 'domed', 'divided', 'arches', 'stiff', '\\n', 'sections', '.', ' ', 'bedding', 'hardly', 'able', 'cover', 'ready', '\\n', 'slide', 'moment', '.', ' ', 'legs', ',', 'pitifully', 'thin', 'compared', '\\n', 'size', 'rest', ',', 'waved', 'helplessly', '\\n', 'looked', '.', '\\n\\n', '\"', 'happened', '?', '\"', 'thought', '.', ' ', 'dream', '.', ' ', 'room', ',', '\\n', 'proper', 'human', 'room', 'little', 'small', ',', 'lay', 'peacefully', '\\n', 'familiar', 'walls', '.', ' ', 'collection', 'textile', 'samples', '\\n', 'lay', 'spread', 'table', '-', 'Samsa', 'travelling', 'salesman']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = [token.text for token in doc_ if not token.is_stop]\n",
    "print(word_tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['morning', 'Gregor', 'Samsa', 'woke', 'troubled', 'dreams', 'found', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armour', 'like', 'lifted', 'head', 'little', 'brown', 'belly', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections', 'bedding', 'hardly', 'able', 'cover', 'ready', 'slide', 'moment', 'legs', 'pitifully', 'thin', 'compared', 'size', 'rest', 'waved', 'helplessly', 'looked', 'happened', 'thought', 'dream', 'room', 'proper', 'human', 'room', 'little', 'small', 'lay', 'peacefully', 'familiar', 'walls', 'collection', 'textile', 'samples', 'lay', 'spread', 'table', 'Samsa', 'travelling', 'salesman', 'hung', 'picture', 'recently', 'cut', 'illustrated', 'magazine', 'housed', 'nice', 'gilded', 'frame', 'showed', 'lady', 'fitted', 'fur', 'hat', 'fur', 'boa', 'sat', 'upright', 'raising', 'heavy', 'fur', 'muff', 'covered', 'lower', 'arm', 'viewer', 'Gregor', 'turned', 'look', 'window', 'dull', 'weather', 'Drops', 'rain', 'heard', 'hitting']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = [token.text for token in doc_ if not token.is_stop and token.is_alpha]\n",
    "print(word_tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['morning', 'gregor', 'samsa', 'wake', 'troubled', 'dream', 'find', 'transform', 'bed', 'horrible', 'vermin', 'lie', 'armour', 'like', 'lift', 'head', 'little', 'brown', 'belly', 'slightly', 'domed', 'divide', 'arch', 'stiff', 'section', 'bedding', 'hardly', 'able', 'cover', 'ready', 'slide', 'moment', 'leg', 'pitifully', 'thin', 'compare', 'size', 'rest', 'wave', 'helplessly', 'look', 'happen', 'think', 'dream', 'room', 'proper', 'human', 'room', 'little', 'small', 'lie', 'peacefully', 'familiar', 'wall', 'collection', 'textile', 'sample', 'lie', 'spread', 'table', 'samsa', 'travel', 'salesman', 'hang', 'picture', 'recently', 'cut', 'illustrate', 'magazine', 'house', 'nice', 'gild', 'frame', 'show', 'lady', 'fit', 'fur', 'hat', 'fur', 'boa', 'sit', 'upright', 'raise', 'heavy', 'fur', 'muff', 'cover', 'low', 'arm', 'viewer', 'gregor', 'turn', 'look', 'window', 'dull', 'weather', 'drop', 'rain', 'hear', 'hit']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = [token.lemma_.lower() for token in doc_ if not token.is_stop and token.is_alpha]\n",
    "print(word_tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'morning gregor samsa wake troubled dream find transform bed horrible vermin lie armour like lift head little brown belly slightly domed divide arch stiff section bedding hardly able cover ready slide moment leg pitifully thin compare size rest wave helplessly look happen think dream room proper human room little small lie peacefully familiar wall collection textile sample lie spread table samsa travel salesman hang picture recently cut illustrate magazine house nice gild frame show lady fit fur hat fur boa sit upright raise heavy fur muff cover low arm viewer gregor turn look window dull weather drop rain hear hit pane feel sad sleep little bit long forget nonsense think unable sleep right present state position hard throw right roll try time shut eye look flounder leg stop begin feel mild dull pain feel oh god think strenuous career choose travel day day business like take effort business home curse travel worry make train connection bad irregular food contact different people time know friendly hell feel slight itch belly push slowly headboard lift head well find itch see cover lot little white spot know try feel place leg draw quickly soon touch overcome cold shudder slide position get early time'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(word_tokens[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet is a lexical database for the English language that can be used to find word meanings, synonyms, antonyms, ...\n",
    "\n",
    "Here are some examples: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Print all elements of synsets of the word **\"happiness\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('happiness.n.01'), Synset('happiness.n.02')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_happiness = wn.synsets('happiness')\n",
    "syn_happiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives the different synonyms (synset) of the word 'happiness' by specifying the nature: noun (n), verb (v),...\n",
    "\n",
    "A synset is a set of synonyms that share a common meaning. \n",
    "\n",
    "Each synset contains one or more lemmas, which represent a specific sense of a specific word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties of the first synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First synonym is :  happiness.n.01\n",
      "Definition of that first synset :  state of well-being characterized by emotions ranging from contentment to intense joy\n",
      "Synonyms (lemmas) : [Lemma('happiness.n.01.happiness'), Lemma('happiness.n.01.felicity')] \n",
      " happiness\n",
      "Example of the word in use in sentences :  []\n"
     ]
    }
   ],
   "source": [
    "print('First synonym is : ', syn_happiness[0].name())\n",
    "print('Definition of that first synset : ', syn_happiness[0].definition())\n",
    "print('Synonyms (lemmas) :' , syn_happiness[0].lemmas(), '\\n', syn_happiness[0].lemmas()[0].name())\n",
    "print('Example of the word in use in sentences : ', syn_happiness[0].examples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All synonyms and antonyms for the word \"happiness\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms of love :  \n",
      " {'happiness', 'felicity'} \n",
      "\n",
      "Antonyms of love :  \n",
      " {'unhappiness', 'sadness'}\n"
     ]
    }
   ],
   "source": [
    "synonyms = [] \n",
    "antonyms = [] \n",
    "  \n",
    "for syn in syn_happiness : \n",
    "    for l in syn.lemmas(): \n",
    "        synonyms.append(l.name()) \n",
    "        if l.antonyms(): \n",
    "            antonyms.append(l.antonyms()[0].name()) \n",
    "  \n",
    "print('Synonyms of love : ', '\\n', set(synonyms), '\\n') \n",
    "print('Antonyms of love : ', '\\n',set(antonyms)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All available language in wordnet\n",
    "\n",
    "The WordNet corpus reader gives access to the Open Multilingual WordNet,\n",
    "using ISO-639 language codes.\n",
    "\n",
    "So we can get word synonyms in another language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language codes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language codes : \n",
      " dict_keys(['eng', 'als', 'arb', 'bul', 'cmn', 'dan', 'ell', 'fin', 'fra', 'heb', 'hrv', 'isl', 'ita', 'ita_iwn', 'jpn', 'cat', 'eus', 'glg', 'spa', 'ind', 'zsm', 'nld', 'nno', 'nob', 'pol', 'por', 'ron', 'lit', 'slk', 'slv', 'swe', 'tha'])\n"
     ]
    }
   ],
   "source": [
    "print('Language codes :','\\n', wn.langs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get lemma name of the first synset of the word **\"happiness\"** in Japanese, Arabic and Fransh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Japanese :\n",
      " {'果報', '幸', '幸い', '幸せ', '清福', '福禄', '利福', '倖せ', '倖', '仕合わせ', '福', '慶福', '幸福'}\n",
      "For Arabic :\n",
      " {'هناء', 'نعِيم', 'سرور', 'بهْجة', 'سعادة'}\n",
      "For Frensh:\n",
      " {'joie', 'bonheur', 'félicité'}\n"
     ]
    }
   ],
   "source": [
    "print('For Japanese :\\n',set(syn_happiness[0].lemma_names('jpn')))\n",
    "print('For Arabic :\\n',set(syn_happiness[0].lemma_names('arb')))\n",
    "print('For Frensh:\\n',set(syn_happiness[0].lemma_names('fra')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Similarity measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Similarity measures With Wordnet (NLTK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sets of synonyms of cat : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('happy.a.01'),\n",
       " Synset('felicitous.s.02'),\n",
       " Synset('glad.s.02'),\n",
       " Synset('happy.s.04')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('happiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sets of synonyms of dog : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('health.n.01'), Synset('health.n.02')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('health')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sets of synonyms of car : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('home.n.01'),\n",
       " Synset('dwelling.n.01'),\n",
       " Synset('home.n.03'),\n",
       " Synset('home_plate.n.01'),\n",
       " Synset('base.n.14'),\n",
       " Synset('home.n.06'),\n",
       " Synset('home.n.07'),\n",
       " Synset('family.n.01'),\n",
       " Synset('home.n.09'),\n",
       " Synset('home.v.01'),\n",
       " Synset('home.v.02'),\n",
       " Synset('home.a.01'),\n",
       " Synset('home.a.02'),\n",
       " Synset('home.s.03'),\n",
       " Synset('home.r.01'),\n",
       " Synset('home.r.02'),\n",
       " Synset('home.r.03')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('home')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity measures :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness = wn.synset('happiness.n.01') #\n",
    "health = wn.synset('health.n.01')\n",
    "home = wn.synset('home.n.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**path_similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between cat and dog :  0.09090909090909091\n",
      "Similarity between dog and car :  0.0625\n",
      "Similarity between car and cat :  0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "print('Similarity between cat and dog : ', happiness.path_similarity(health))\n",
    "print('Similarity between dog and car : ', health.path_similarity(happiness))\n",
    "print('Similarity between car and cat : ', home.path_similarity(health))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lch_similarity** : Leacock-Chodorow Similarity (Leacock and Chodorow 1998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between cat and dog :  1.2396908869280152\n",
      "Similarity between dog and car :  0.7472144018302211\n",
      "Similarity between car and cat :  0.8649974374866046\n"
     ]
    }
   ],
   "source": [
    "print('Similarity between happiness and health : ', happiness.lch_similarity(health))\n",
    "print('Similarity between health and home : ', health.lch_similarity(home))\n",
    "print('Similarity between home and happiness : ', home.lch_similarity(happiness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**wup_similarity** : Wu-Palmer Similarity (Wu and Palmer 1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between cat and dog :  0.4444444444444444\n",
      "Similarity between dog and car :  0.10526315789473684\n",
      "Similarity between car and cat :  0.11764705882352941\n"
     ]
    }
   ],
   "source": [
    "print('Similarity between happiness and health : ', happiness.wup_similarity(health))\n",
    "print('Similarity between health and home : ', health.wup_similarity(home))\n",
    "print('Similarity between home and happiness : ', home.wup_similarity(happiness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Similarity measures With SpaCy\n",
    "\n",
    "Based on coisnus similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between happiness and health :  0.41790983756817446\n",
      "Similarity between health and home :  0.2936136163478605\n",
      "Similarity between home and happiness :  0.3032258847207985\n"
     ]
    }
   ],
   "source": [
    "print('Similarity between happiness and health : ', nlp('happiness').similarity(nlp('health')))\n",
    "print('Similarity between health and home : ', nlp('health').similarity(nlp('home')))\n",
    "print('Similarity between home and happiness : ', nlp('home').similarity(nlp('happiness')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# TextBlob : sentiment analysis, translation, TF-IDF Aanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is a beautiful high-level, general-purpose programming language !\n"
     ]
    }
   ],
   "source": [
    "textblob_python = TextBlob(\"Python is a beautiful high-level, general-purpose programming language !\")\n",
    "print(textblob_python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('high-level', 'NN'),\n",
       " ('general-purpose', 'JJ'),\n",
       " ('programming', 'NN'),\n",
       " ('language', 'NN')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob_python.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> this gives the function of each word like nltk.pos_tag and token.pos_ token.tag_ for SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['python', 'beautiful high-level'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob_python.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris is so beautiful, I like Paris, peopel are so nice !\n"
     ]
    }
   ],
   "source": [
    "textblob_paris = TextBlob('Paris is so beautiful, I like Paris, peopel are so nice !')\n",
    "print(textblob_paris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.8, subjectivity=1.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob_paris.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> the sentence have a positive sentiment (positive polarity = 0.8 > 0 and close to 1) and it's very subjective (subjectivity = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## **Wikipedia text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = '''\n",
    "\"During the Iron Age, what is\n",
    "now metropolitan France was inhabited by the Gauls, a Celtic people. Rome\n",
    "annexed the area in 51 BC, holding it until the arrival of Germanic Franks\n",
    "in 476, who formed the Kingdom of Francia. The Treaty of Verdun of 843\n",
    "partitioned Francia into East Francia, Middle Francia and West Francia.West Francia, which became the Kingdom of France in 987, emerged as a\n",
    "major European power in the Late Middle Ages, following its victory in the\n",
    "Hundred Years' War (1337\u00151453). During the Renaissance, French culture\n",
    "fourished and a global colonial empire was established, which by the 20th\n",
    "century would become the second largest in the world. The 16th century\n",
    "was dominated by religious civil wars between Catholics and Protestants\n",
    "(Huguenots). France became Europe's dominant cultural, political, and military power in the 17th century under Louis XIV. In the late 18th century,\n",
    "the French Revolution overthrew the absolute monarchy, establishing one of\n",
    "modern history's earliest republics and drafting the Declaration of the Rights\n",
    "of Man and of the Citizen, which expresses the nation's ideals to this day.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert wiki to extBlob object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"\n",
       "\"During the Iron Age, what is\n",
       "now metropolitan France was inhabited by the Gauls, a Celtic people. Rome\n",
       "annexed the area in 51 BC, holding it until the arrival of Germanic Franks\n",
       "in 476, who formed the Kingdom of Francia. The Treaty of Verdun of 843\n",
       "partitioned Francia into East Francia, Middle Francia and West Francia.West Francia, which became the Kingdom of France in 987, emerged as a\n",
       "major European power in the Late Middle Ages, following its victory in the\n",
       "Hundred Years' War (1337\u00151453). During the Renaissance, French culture\n",
       "\n",
       "ourished and a global colonial empire was established, which by the 20th\n",
       "century would become the second largest in the world. The 16th century\n",
       "was dominated by religious civil wars between Catholics and Protestants\n",
       "(Huguenots). France became Europe's dominant cultural, political, and military power in the 17th century under Louis XIV. In the late 18th century,\n",
       "the French Revolution overthrew the absolute monarchy, establishing one of\n",
       "modern history's earliest republics and drafting the Declaration of the Rights\n",
       "of Man and of the Citizen, which expresses the nation's ideals to this day.\")\n",
       "\")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_wiki = TextBlob(wiki)\n",
    "blob_wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## words and sentences of wikipedia text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Words of the wikipedia text : \n",
      " ['During', 'the', 'Iron', 'Age', 'what', 'is', 'now', 'metropolitan', 'France', 'was', 'inhabited', 'by', 'the', 'Gauls', 'a', 'Celtic', 'people', 'Rome', 'annexed', 'the', 'area', 'in', '51', 'BC', 'holding', 'it', 'until', 'the', 'arrival', 'of', 'Germanic', 'Franks', 'in', '476', 'who', 'formed', 'the', 'Kingdom', 'of', 'Francia', 'The', 'Treaty', 'of', 'Verdun', 'of', '843', 'partitioned', 'Francia', 'into', 'East', 'Francia', 'Middle', 'Francia', 'and', 'West', 'Francia.West', 'Francia', 'which', 'became', 'the', 'Kingdom', 'of', 'France', 'in', '987', 'emerged', 'as', 'a', 'major', 'European', 'power', 'in', 'the', 'Late', 'Middle', 'Ages', 'following', 'its', 'victory', 'in', 'the', 'Hundred', 'Years', 'War', '1337\\x151453', 'During', 'the', 'Renaissance', 'French', 'culture', 'ourished', 'and', 'a', 'global', 'colonial', 'empire', 'was', 'established', 'which', 'by', 'the', '20th', 'century', 'would', 'become', 'the', 'second', 'largest', 'in', 'the', 'world', 'The', '16th', 'century', 'was', 'dominated', 'by', 'religious', 'civil', 'wars', 'between', 'Catholics', 'and', 'Protestants', 'Huguenots', 'France', 'became', 'Europe', \"'s\", 'dominant', 'cultural', 'political', 'and', 'military', 'power', 'in', 'the', '17th', 'century', 'under', 'Louis', 'XIV', 'In', 'the', 'late', '18th', 'century', 'the', 'French', 'Revolution', 'overthrew', 'the', 'absolute', 'monarchy', 'establishing', 'one', 'of', 'modern', 'history', \"'s\", 'earliest', 'republics', 'and', 'drafting', 'the', 'Declaration', 'of', 'the', 'Rights', 'of', 'Man', 'and', 'of', 'the', 'Citizen', 'which', 'expresses', 'the', 'nation', \"'s\", 'ideals', 'to', 'this', 'day'] \n",
      "\n",
      "Sentences of the wikipedia text : \n",
      " [Sentence(\"\n",
      "\"During the Iron Age, what is\n",
      "now metropolitan France was inhabited by the Gauls, a Celtic people.\"), Sentence(\"Rome\n",
      "annexed the area in 51 BC, holding it until the arrival of Germanic Franks\n",
      "in 476, who formed the Kingdom of Francia.\"), Sentence(\"The Treaty of Verdun of 843\n",
      "partitioned Francia into East Francia, Middle Francia and West Francia.West Francia, which became the Kingdom of France in 987, emerged as a\n",
      "major European power in the Late Middle Ages, following its victory in the\n",
      "Hundred Years' War (1337\u00151453).\"), Sentence(\"During the Renaissance, French culture\n",
      "\u001d",
      "ourished and a global colonial empire was established, which by the 20th\n",
      "century would become the second largest in the world.\"), Sentence(\"The 16th century\n",
      "was dominated by religious civil wars between Catholics and Protestants\n",
      "(Huguenots).\"), Sentence(\"France became Europe's dominant cultural, political, and military power in the 17th century under Louis XIV.\"), Sentence(\"In the late 18th century,\n",
      "the French Revolution overthrew the absolute monarchy, establishing one of\n",
      "modern history's earliest republics and drafting the Declaration of the Rights\n",
      "of Man and of the Citizen, which expresses the nation's ideals to this day.\")\")]\n"
     ]
    }
   ],
   "source": [
    "print('\\n Words of the wikipedia text : \\n', blob_wiki.words, '\\n')\n",
    "print('Sentences of the wikipedia text :', '\\n', blob_wiki.sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sentiment analysis for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=-0.03958333333333333, subjectivity=0.20000000000000004)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.25)\n",
      "Sentiment(polarity=0.0, subjectivity=0.10000000000000002)\n",
      "Sentiment(polarity=0.02500000000000001, subjectivity=0.45)\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob_wiki.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Translate the wikipedia text to french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"\"Pendant l'âge du fer, ce qui est\n",
       "Maintenant, la France métropolitaine était habitée par les Gaulois, un peuple celtique. Rome\n",
       "annexé la zone en 51 avant JC, la tenant jusqu'à l'arrivée de Franks germaniques\n",
       "en 476, qui a formé le royaume de Francia. Le traité de Verdun de 843\n",
       "Francia partitionné dans East Francia, Middle Francia et West Francia.\n",
       "Principale puissance européenne à la fin du Moyen Âge, après sa victoire dans le\n",
       "Cent ans de guerre (1337 1453). Pendant la Renaissance, la culture française\n",
       "ourous et un empire colonial mondial ont été créés, qui au 20\n",
       "Century deviendrait le deuxième plus grand au monde. Le XVIe siècle\n",
       "était dominé par les guerres civiles religieuses entre catholiques et protestants\n",
       "(Huguenots). La France est devenue la puissance culturelle, politique et militaire dominante d'Europe au 17ème siècle sous Louis XIV. À la fin du XVIIIe siècle,\n",
       "La Révolution française a renversé la monarchie absolue, établissant l'un des\n",
       "Les premières républiques de l'histoire moderne et rédaction de la déclaration des droits\n",
       "de l'homme et du citoyen, qui exprime les idéaux de la nation à ce jour. \")\")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_wiki.translate(from_lang = 'en', to='fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"\"خلال العصر الحديدي ، ما هو\n",
       "الآن ، كان غالولز في فرنسا متروبوليتان ، وهو شعب سلتيك. روما\n",
       "ضم المنطقة في 51 قبل الميلاد ، ممسكة بها حتى وصول الفرنجة الجرمانية\n",
       "في 476 ، الذين شكلوا مملكة فرانسيا. معاهدة فيردون من 843\n",
       "قامت فرانسيا بتقسيم إلى شرق فرانسيا ووسط فرانسيا وغرب فرانسيا. غرب فرانسيا ، التي أصبحت مملكة فرنسا في عام 987 ، ظهرت كـ\n",
       "القوة الأوروبية الرئيسية في أواخر العصور الوسطى ، بعد فوزها في\n",
       "حرب مائة عام (1337 1453). خلال عصر النهضة ، الثقافة الفرنسية\n",
       "تم إنشاء إمبراطورية الاستعمارية العالمية الخاصة بنا ، والتي بحلول العشرين\n",
       "سيصبح القرن ثاني أكبر أكبر في العالم. القرن السادس عشر\n",
       "سيطر عليها الحروب الأهلية الدينية بين الكاثوليك والبروتستانت\n",
       "(Huguenots). أصبحت فرنسا القوة الثقافية والسياسية والعسكرية السائدة في أوروبا في القرن السابع عشر تحت قيادة لويس الرابع عشر. في أواخر القرن الثامن عشر ،\n",
       "أطاحت الثورة الفرنسية بالملكية المطلقة ، وتأسيس واحدة من\n",
       "أول جمهوريات للتاريخ الحديث وصياغة إعلان الحقوق\n",
       "من الرجل والمواطن ، الذي يعبر عن مُثُل الأمة حتى يومنا هذا. \")\")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_wiki.translate(from_lang = 'en', to='ar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## TF-IDF analysis with textblob and wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **tf** function : takes into parameter a word and a blobtext and returns the word frequency inside the textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, blobtext):\n",
    "    if not isinstance(word,str):\n",
    "      word = str(word)\n",
    "    return(blobtext.words.count(word) / len(blobtext.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- verification of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18181818181818182"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob_paris = TextBlob('Paris is so beautiful, I like Paris, peopel are so nice !')\n",
    "tf('paris', textblob_paris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **n_containing** function :  takes into parameters a word and a textblob list and returns the occurrence of this word in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_containing(word, bloblist):\n",
    "    c=0\n",
    "    for blob in bloblist :\n",
    "        if (blob.words.count(word)!=0):\n",
    "            c+=1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Verification of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextBlob(\"Paris is so beautiful, I like Paris, peopel are so nice !\"),\n",
       " TextBlob(\"Paris is always a good idea\"),\n",
       " TextBlob(\"Just add three letters to Paris, and you have paradise\"),\n",
       " TextBlob(\"London is a riddle. Paris is an explanation\")]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bloblist contains some famous Paris quotes\n",
    "bloblist= [textblob_paris,\n",
    "           TextBlob('Paris is always a good idea'),#Audrey Hepburn,\n",
    "           TextBlob('Just add three letters to Paris, and you have paradise'), #Jules Renard\n",
    "           TextBlob('London is a riddle. Paris is an explanation') #G. K. Chesterson\n",
    "          ]\n",
    "bloblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_containing('paris', bloblist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **idf** function : takes into parameters a word and a textblob list and returns the inverse document frequency for the word passed as parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word,bloblist):\n",
    "    return(math.log((len(bloblist)/n_containing(word, bloblist))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf('paris',bloblist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **tfidf** function: takes into parameter, a word, a textbloc and a textblob list. This function must return the Term Frequency Inverse Document Frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = textblob_paris\n",
    "bloblist= bloblist\n",
    "tfidf('paris',blob,bloblist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> All documents have the word 'Paris'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## TextBlob from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextBlob(\"France (French: [fʁɑ̃s] ), officially the French Republic (French: République française), is a transcontinental country predominantly located in Western Europe and spanning overseas regions and territories in the Americas and the Atlantic, Pacific and Indian Oceans. Its metropolitan area extends from the Rhine to the Atlantic Ocean and from the Mediterranean Sea to the English Channel and the North Sea; overseas territories include French Guiana in South America, Saint Pierre and Miquelon in the North Atlantic, the French West Indies, and many islands in Oceania and the Indian Ocean. Due to its several coastal territories, France has the largest exclusive economic zone in the world. France borders Belgium, Luxembourg, Germany, Switzerland, Monaco, Italy, Andorra, and Spain in continental Europe, as well as the Netherlands, Suriname, and Brazil in the Americas via its overseas territories in French Guiana and Saint Martin. Its eighteen integral regions (five of which are overseas) span a combined area of 643,801 km2 (248,573 sq mi) and close to 68 million people (as of July 2022). France is a unitary semi-presidential republic with its capital in Paris, the country's largest city and main cultural and commercial centre; other major urban areas include Marseille, Lyon, Toulouse, Lille, Bordeaux, and Nice.\n",
       " Inhabited since the Palaeolithic era, the territory of Metropolitan France was settled by Celtic tribes known as Gauls during the Iron Age. Rome annexed the area in 51 BC, leading to a distinct Gallo-Roman culture that laid the foundation of the French language. The Germanic Franks formed the Kingdom of Francia, which became the heartland of the Carolingian Empire. The Treaty of Verdun of 843 partitioned the empire, with West Francia becoming the Kingdom of France in 987. In the High Middle Ages, France was a powerful but highly decentralised feudal kingdom. Philip II successfully strengthened royal power and defeated his rivals to double the size of the crown lands; by the end of his reign, France had emerged as the most powerful state in Europe. From the mid-14th to the mid-15th century, France was plunged into a series of dynastic conflicts involving England, collectively known as the Hundred Years' War, and a distinct French identity emerged as a result. The French Renaissance saw art and culture flourish, conflict with the House of Habsburg, and the establishment of a global colonial empire, which by the 20th century would become the second-largest in the world. The second half of the 16th century was dominated by religious civil wars between Catholics and Huguenots that severely weakened the country. France again emerged as Europe's dominant power in the 17th century under Louis XIV following the Thirty Years' War. Inadequate economic policies, inequitable taxes and frequent wars (notably a defeat in the Seven Years' War and costly involvement in the American War of Independence), left the kingdom in a precarious economic situation by the end of the 18th century. This precipitated the French Revolution of 1789, which overthrew the Ancien Régime and produced the Declaration of the Rights of Man, which expresses the nation's ideals to this day.\n",
       " France reached its political and military zenith in the early 19th century under Napoleon Bonaparte, subjugating much of continental Europe and establishing the First French Empire. The French Revolutionary and Napoleonic Wars shaped the course of European and world history. The collapse of the empire initiated a period of relative decline, in which France endured a tumultuous succession of governments until the founding of the French Third Republic during the Franco-Prussian War in 1870. Subsequent decades saw a period of optimism, cultural and scientific flourishing, as well as economic prosperity known as the Belle Époque. France was one of the major participants of World War I, from which it emerged victorious at great human and economic cost. It was among the Allied powers of World War II, but was soon occupied by the Axis in 1940. Following liberation in 1944, the short-lived Fourth Republic was established and later dissolved in the course of the Algerian War. The current Fifth Republic was formed in 1958 by Charles de Gaulle. Algeria and most French colonies became independent in the 1960s, with the majority retaining close economic and military ties with France.\n",
       " France retains its centuries-long status as a global centre of art, science and philosophy. It hosts the fifth-largest number of UNESCO World Heritage Sites and is the world's leading tourist destination, receiving over 89 million foreign visitors in 2018. France is a developed country with the world's seventh-largest economy by nominal GDP and tenth-largest by PPP; in terms of aggregate household wealth, it ranks fourth in the world. France performs well in international rankings of education, health care, life expectancy and human development. It remains a great power in global affairs, being one of the five permanent members of the United Nations Security Council and an official nuclear-weapon state. France is a founding and leading member of the European Union and the Eurozone, as well as a key member of the Group of Seven, North Atlantic Treaty Organization (NATO), Organisation for Economic Co-operation and Development (OECD) and La Francophonie.\"),\n",
       " TextBlob(\"Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.Python is dynamically-typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0. Python 2.0 was released in 2000 and introduced new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support. Python 3.0, released in 2008, was a major revision that is not completely backward-compatible with earlier versions. Python 2 was discontinued with version 2.7.18 in 2020.Python consistently ranks as one of the most popular programming languages.\"),\n",
       " TextBlob(\"A box (plural: boxes) is a container used for the storage or transportation of its contents. Most boxes have flat, parallel, rectangular sides. Boxes can be very small (like a matchbox) or very large (like a shipping box for furniture), and can be used for a variety of purposes from functional to decorative. \n",
       " Boxes may be made of a variety of materials, both durable, such as wood and metal; and non-durable, such as corrugated fiberboard and paperboard. Corrugated metal boxes are commonly used as shipping containers.\n",
       " Most commonly, boxes have flat, parallel, rectangular sides, making them rectangular prisms; but boxes may also have other shapes. Rectangular prisms are often referred to colloquially as \"boxes.\"\n",
       " Boxes may be closed and shut with flaps, doors, or a separate lid. They can be secured shut with adhesives, tapes, or more decorative or elaborately functional mechanisms, such as a catch, clasp or lock.\n",
       " \n",
       " \"),\n",
       " TextBlob(\"Sir Isaac Newton  (25 December 1642 – 20 March 1726/27) was an English mathematician, physicist, astronomer, alchemist, theologian, and author (described in his time as a \"natural philosopher\"), widely recognised as one of the greatest mathematicians and physicists and among the most influential scientists of all time. He was a key figure in the philosophical revolution known as the Enlightenment. His book Philosophiæ Naturalis Principia Mathematica (Mathematical Principles of Natural Philosophy), first published in 1687, established classical mechanics. Newton also made seminal contributions to optics, and shares credit with German mathematician Gottfried Wilhelm Leibniz for developing infinitesimal calculus.\n",
       " In the Principia, Newton formulated the laws of motion and universal gravitation that formed the dominant scientific viewpoint until it was superseded by the theory of relativity. Newton used his mathematical description of gravity to derive Kepler's laws of planetary motion, account for tides, the trajectories of comets, the precession of the equinoxes and other phenomena, eradicating doubt about the Solar System's heliocentricity. He demonstrated that the motion of objects on Earth and celestial bodies could be accounted for by the same principles. Newton's inference that the Earth is an oblate spheroid was later confirmed by the geodetic measurements of Maupertuis, La Condamine, and others, convincing most European scientists of the superiority of Newtonian mechanics over earlier systems.\n",
       " Newton built the first practical reflecting telescope and developed a sophisticated theory of colour based on the observation that a prism separates white light into the colours of the visible spectrum. His work on light was collected in his highly influential book Opticks, published in 1704. He also formulated an empirical law of cooling, made the first theoretical calculation of the speed of sound, and introduced the notion of a Newtonian fluid. In addition to his work on calculus, as a mathematician Newton contributed to the study of power series, generalised the binomial theorem to non-integer exponents, developed a method for approximating the roots of a function, and classified most of the cubic plane curves.\n",
       " Newton was a fellow of Trinity College and the second Lucasian Professor of Mathematics at the University of Cambridge.\n",
       " Newton was a devout but unorthodox Christian who privately rejected the doctrine of the Trinity. He refused to take holy orders in the Church of England, unlike most members of the Cambridge faculty of the day. Beyond his work on the mathematical sciences, Newton dedicated much of his time to the study of alchemy and biblical chronology, but most of his work in those areas remained unpublished until long after his death. Politically and personally tied to the Whig party, Newton served two brief terms as Member of Parliament for the University of Cambridge, in 1689–1690 and 1701–1702. He was knighted by Queen Anne in 1705 and spent the last three decades of his life in London, serving as Warden (1696–1699) and Master (1699–1727) of the Royal Mint, as well as president of the Royal Society (1703–1727).\n",
       " \n",
       " \"),\n",
       " TextBlob(\"Zinedine Yazid Zidane (born 23 June 1972), popularly known as Zizou, is a French professional football manager and former player who played as an attacking midfielder. He most recently coached Spanish club Real Madrid and is one of the most successful coaches in the world. Also widely regarded as one of the greatest players of all time, Zidane was a playmaker renowned for his elegance, vision, passing, ball control and technique. He received many individual accolades as a player, including being named FIFA World Player of the Year in 1998, 2000 and 2003, and winning the 1998 Ballon d'Or.\n",
       " Zidane started his career at Cannes before establishing himself as one of the best players in the French Ligue 1 at Bordeaux. In 1996, he moved to Italian team Juventus, where he won several trophies including two Serie A titles. He moved to Real Madrid for a world record fee at the time of €77.5 million in 2001, which remained unmatched for the next eight years. In Spain, Zidane won several trophies, including a La Liga title and the UEFA Champions League. In the 2002 Champions League final, he scored a left-foot volleyed winner which is considered to be one of the greatest goals in the competition's history.\n",
       " Capped 108 times by France, Zidane won the 1998 FIFA World Cup, scoring twice in the final, and was named to the All-Star team. This triumph made him a national hero in France and he received the Legion of Honour in 1998. He won UEFA Euro 2000 and was named Player of the Tournament. He also received the Golden Ball as Player of the Tournament at the 2006 World Cup, despite his infamous sending off in the final against Italy for headbutting Marco Materazzi in the chest. He retired as the fourth-most capped player in French history.\n",
       " In 2004, he was named in the FIFA 100, a list of the world's greatest living players compiled by Pelé, and in the same year was named the best European footballer of the past 50 years in the UEFA Golden Jubilee Poll. Zidane is one of eight players to have won the World Cup, the Champions League and the Ballon d'Or. He was the ambassador for Qatar's successful bid to stage the 2022 World Cup, the first Arab country to host the tournament.\n",
       " After retiring as a player, Zidane began his coaching career at Real Madrid Castilla. He remained in the position for two years before taking the helm of the first team in 2016. In his initial two and a half seasons, Zidane became the first coach to win the Champions League three times in a row, won the UEFA Super Cup and FIFA Club World Cup twice each, as well as a La Liga title and a Supercopa de España. This success led to Zidane being named Best FIFA Men's Coach in 2017. He resigned in 2018, but returned to the club in 2019 and proceeded to win another La Liga and a Supercopa de España title. He left the club once again in 2021.\")]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloblist_wiki=[]\n",
    "topics = [\"France\",\"Python (programming language)\", \"Fox\", \"Isaac Newton\", \"Zinedine Zidane\" ]\n",
    "for topic in topics :\n",
    "    bloblist_wiki.append(TextBlob(wikipedia.summary(topic)))\n",
    "\n",
    "bloblist_wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Wikipedia Text preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the stopwords, change everything to lower case, and create a bag of words containing all other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1290 words\n",
      "['france', 'french', 'fʁɑ̃s', 'officially', 'french', 'republic', 'french', 'république', 'française', 'transcontinental', 'country', 'predominantly', 'located', 'western', 'europe', 'spanning', 'overseas', 'regions', 'territories', 'americas', 'atlantic', 'pacific', 'indian', 'oceans', 'metropolitan', 'area', 'extends', 'rhine', 'atlantic', 'ocean', 'mediterranean', 'sea', 'english', 'channel', 'north', 'sea', 'overseas', 'territories', 'include', 'french', 'guiana', 'south', 'america', 'saint', 'pierre', 'miquelon', 'north', 'atlantic', 'french', 'west', 'indies', 'many', 'islands', 'oceania', 'indian', 'ocean', 'due', 'several', 'coastal', 'territories', 'france', 'largest', 'exclusive', 'economic', 'zone', 'world', 'france', 'borders', 'belgium', 'luxembourg', 'germany', 'switzerland', 'monaco', 'italy', 'andorra', 'spain', 'continental', 'europe', 'well', 'netherlands', 'suriname', 'brazil', 'americas', 'via', 'overseas', 'territories', 'french', 'guiana', 'saint', 'martin', 'eighteen', 'integral', 'regions', 'five', 'overseas', 'span', 'combined', 'area', '643,801', 'km2', '248,573', 'sq', 'mi', 'close', '68', 'million', 'people', 'july', '2022', 'france', 'unitary', 'semi-presidential', 'republic', 'capital', 'paris', 'country', \"'s\", 'largest', 'city', 'main', 'cultural', 'commercial', 'centre', 'major', 'urban', 'areas', 'include', 'marseille', 'lyon', 'toulouse', 'lille', 'bordeaux', 'nice', 'inhabited', 'since', 'palaeolithic', 'era', 'territory', 'metropolitan', 'france', 'settled', 'celtic', 'tribes', 'known', 'gauls', 'iron', 'age', 'rome', 'annexed', 'area', '51', 'bc', 'leading', 'distinct', 'gallo-roman', 'culture', 'laid', 'foundation', 'french', 'language', 'germanic', 'franks', 'formed', 'kingdom', 'francia', 'became', 'heartland', 'carolingian', 'empire', 'treaty', 'verdun', '843', 'partitioned', 'empire', 'west', 'francia', 'becoming', 'kingdom', 'france', '987', 'high', 'middle', 'ages', 'france', 'powerful', 'highly', 'decentralised', 'feudal', 'kingdom', 'philip', 'ii', 'successfully', 'strengthened', 'royal', 'power', 'defeated', 'rivals', 'double', 'size', 'crown']\n"
     ]
    }
   ],
   "source": [
    "en_stops = stopwords.words('english')\n",
    "\n",
    "bag_of_other_words = []  \n",
    "for blob in bloblist:  \n",
    "    for w in blob.words.lower():  #change all words to lower case\n",
    "        if w not in en_stops: # remove stopwords\n",
    "            bag_of_other_words.append(w) \n",
    "print('We have {} words'.format(len(bag_of_other_words)))\n",
    "print(bag_of_other_words[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Compute the TF-IDF of all words for all documents in the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will create a dictionary containing the word and its tfidf mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('france', 0.0035584106092200196),\n",
       " ('french', 0.00533761591383003),\n",
       " ('fʁɑ̃s', 0.0),\n",
       " ('officially', 0.0),\n",
       " ('republic', 0.0),\n",
       " ('république', 0.0),\n",
       " ('française', 0.0),\n",
       " ('transcontinental', 0.0),\n",
       " ('country', 0.0017792053046100098),\n",
       " ('predominantly', 0.0)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tf_idf_wiki.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('france', 0.0035584106092200196), ('french', 0.00533761591383003), ('fʁɑ̃s', 0.0), ('officially', 0.0), ('republic', 0.0), ('république', 0.0), ('française', 0.0), ('transcontinental', 0.0), ('country', 0.0017792053046100098), ('predominantly', 0.0), ('located', 0.0), ('western', 0.0), ('europe', 0.0), ('spanning', 0.0), ('overseas', 0.0), ('regions', 0.0), ('territories', 0.0), ('americas', 0.0), ('atlantic', 0.0), ('pacific', 0.0), ('indian', 0.0), ('oceans', 0.0), ('metropolitan', 0.0), ('area', 0.0), ('extends', 0.0), ('rhine', 0.0), ('ocean', 0.0), ('mediterranean', 0.0), ('sea', 0.0), ('english', 0.0), ('channel', 0.0), ('north', 0.0), ('include', 0.0), ('guiana', 0.0), ('south', 0.0), ('america', 0.0), ('saint', 0.0), ('pierre', 0.0), ('miquelon', 0.0), ('west', 0.0), ('indies', 0.0), ('many', 0.0017792053046100098), ('islands', 0.0), ('oceania', 0.0), ('due', 0.0), ('several', 0.0035584106092200196), ('coastal', 0.0), ('largest', 0.0), ('exclusive', 0.0), ('economic', 0.0), ('zone', 0.0), ('world', 0.01601284774149009), ('borders', 0.0), ('belgium', 0.0), ('luxembourg', 0.0), ('germany', 0.0), ('switzerland', 0.0), ('monaco', 0.0), ('italy', 0.0017792053046100098), ('andorra', 0.0), ('spain', 0.0017792053046100098), ('continental', 0.0), ('well', 0.0009918944150795936), ('netherlands', 0.0), ('suriname', 0.0), ('brazil', 0.0), ('via', 0.0), ('martin', 0.0), ('eighteen', 0.0), ('integral', 0.0), ('five', 0.0), ('span', 0.0), ('combined', 0.0), ('643,801', 0.0), ('km2', 0.0), ('248,573', 0.0), ('sq', 0.0), ('mi', 0.0), ('close', 0.0), ('68', 0.0), ('million', 0.0017792053046100098), ('people', 0.0), ('july', 0.0), ('2022', 0.0017792053046100098), ('unitary', 0.0), ('semi-presidential', 0.0), ('capital', 0.0), ('paris', 0.0), (\"'s\", 0.0039675776603183745), ('city', 0.0), ('main', 0.0), ('cultural', 0.0), ('commercial', 0.0), ('centre', 0.0), ('major', 0.0), ('urban', 0.0), ('areas', 0.0), ('marseille', 0.0), ('lyon', 0.0), ('toulouse', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_wiki={}\n",
    "for word in bag_of_other_words:\n",
    "    for blob in bloblist:\n",
    "        tf_idf_wiki[word] = tfidf(word, blob, bloblist)\n",
    "# print the 100 first words\n",
    "print(list(tf_idf_wiki.items())[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
